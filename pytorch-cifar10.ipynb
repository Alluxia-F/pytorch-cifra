{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data augmentation\n",
    "transform_train=transforms.Compose([\n",
    "    transforms.RandomCrop(32,padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.2,0.2,0.2)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the test set same as training set without augmentation\n",
    "transform_test=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.2,0.2,0.2))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "trainset=torchvision.datasets.CIFAR10(\n",
    "        root='./data',train=True,download=True,transform=transform_train)\n",
    "\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=BATCH_SIZE,shuffle=True,num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load the testing dataset\n",
    "testset=torchvision.datasets.CIFAR10(\n",
    "    root='./data',train=False,download=True,transform=transform_test)\n",
    "testloader=torch.utils.data.DataLoader(testset,batch_size=BATCH_SIZE,shuffle=False,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Convulution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Dropout(p=0.05, inplace=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Dropout(p=0.05, inplace=False)\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Dropout(p=0.05, inplace=False)\n",
       "  )\n",
       "  (gap): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
       "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "LR = 0.005\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    \"\"\"Some Information about CNN\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),  \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1),  \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),  \n",
    "            nn.Dropout(p=0.05,inplace=False)\n",
    "        )\n",
    "        self.conv3 = torch.nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),  \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv4 = torch.nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1),  \n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(p=0.05,inplace=False)\n",
    "        )\n",
    "\n",
    "        self.conv5 = torch.nn.Sequential(\n",
    "            nn.Conv2d(256, 256, 3, padding=1),  \n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),  \n",
    "            nn.Dropout(p=0.05,inplace=False)\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.gap = nn.AvgPool2d(4,4)\n",
    "        self.fc = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(-1, 256)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Loss Function and Optimizer\n",
    "# I choose to use a Classification Cross-Entropy loss and Adam optimizer\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(net.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tain funcion\n",
    "\n",
    "def train(model,criterion,optimizer,trainloader,epochs,log_interval=50):\n",
    "    print('-------- Training job starts ------')\n",
    "    for epoch in range(epochs):\n",
    "        running_loss=0.0\n",
    "        for step,(batch_x,batch_y) in enumerate(trainloader):\n",
    "            batch_x,batch_y=batch_x.cuda(),batch_y.cuda()\n",
    "            output=model(batch_x)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss=criterion(output,batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss+=loss.item()\n",
    "            if step % log_interval == (log_interval-1):\n",
    "                print('[%d, %5d] loss: %.4f' %\n",
    "                      (epoch + 1, step + 1, running_loss / log_interval))\n",
    "                running_loss = 0.0\n",
    "    print('----- Train Finished -----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "def test(model, testloader):\n",
    "    print('------ Test Start -----')\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_x, test_y in testloader:\n",
    "            images, labels = test_x.cuda(), test_y.cuda()\n",
    "            output = model(images)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print('Accuracy of the model is: %.4f %%' % accuracy)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Training job starts ------\n",
      "[1,    50] loss: 1.6755\n",
      "[1,   100] loss: 1.3436\n",
      "[1,   150] loss: 1.2152\n",
      "[2,    50] loss: 1.0463\n",
      "[2,   100] loss: 0.9687\n",
      "[2,   150] loss: 0.9411\n",
      "[3,    50] loss: 0.8471\n",
      "[3,   100] loss: 0.8272\n",
      "[3,   150] loss: 0.8120\n",
      "[4,    50] loss: 0.7347\n",
      "[4,   100] loss: 0.7353\n",
      "[4,   150] loss: 0.6796\n",
      "[5,    50] loss: 0.6517\n",
      "[5,   100] loss: 0.6724\n",
      "[5,   150] loss: 0.6348\n",
      "[6,    50] loss: 0.6004\n",
      "[6,   100] loss: 0.5966\n",
      "[6,   150] loss: 0.5867\n",
      "[7,    50] loss: 0.5603\n",
      "[7,   100] loss: 0.5492\n",
      "[7,   150] loss: 0.5389\n",
      "[8,    50] loss: 0.5048\n",
      "[8,   100] loss: 0.5027\n",
      "[8,   150] loss: 0.5122\n",
      "[9,    50] loss: 0.4802\n",
      "[9,   100] loss: 0.4650\n",
      "[9,   150] loss: 0.4792\n",
      "[10,    50] loss: 0.4513\n",
      "[10,   100] loss: 0.4431\n",
      "[10,   150] loss: 0.4592\n",
      "[11,    50] loss: 0.4185\n",
      "[11,   100] loss: 0.4358\n",
      "[11,   150] loss: 0.4361\n",
      "[12,    50] loss: 0.4083\n",
      "[12,   100] loss: 0.4060\n",
      "[12,   150] loss: 0.4108\n",
      "[13,    50] loss: 0.3863\n",
      "[13,   100] loss: 0.3757\n",
      "[13,   150] loss: 0.3891\n",
      "[14,    50] loss: 0.3666\n",
      "[14,   100] loss: 0.3713\n",
      "[14,   150] loss: 0.3752\n",
      "[15,    50] loss: 0.3581\n",
      "[15,   100] loss: 0.3520\n",
      "[15,   150] loss: 0.3597\n",
      "[16,    50] loss: 0.3387\n",
      "[16,   100] loss: 0.3397\n",
      "[16,   150] loss: 0.3336\n",
      "[17,    50] loss: 0.3168\n",
      "[17,   100] loss: 0.3262\n",
      "[17,   150] loss: 0.3329\n",
      "[18,    50] loss: 0.3092\n",
      "[18,   100] loss: 0.3066\n",
      "[18,   150] loss: 0.3158\n",
      "[19,    50] loss: 0.3012\n",
      "[19,   100] loss: 0.2984\n",
      "[19,   150] loss: 0.3088\n",
      "[20,    50] loss: 0.2792\n",
      "[20,   100] loss: 0.2923\n",
      "[20,   150] loss: 0.2987\n",
      "[21,    50] loss: 0.2749\n",
      "[21,   100] loss: 0.2729\n",
      "[21,   150] loss: 0.2744\n",
      "[22,    50] loss: 0.2653\n",
      "[22,   100] loss: 0.2756\n",
      "[22,   150] loss: 0.2614\n",
      "[23,    50] loss: 0.2686\n",
      "[23,   100] loss: 0.2598\n",
      "[23,   150] loss: 0.2648\n",
      "[24,    50] loss: 0.2438\n",
      "[24,   100] loss: 0.2478\n",
      "[24,   150] loss: 0.2470\n",
      "[25,    50] loss: 0.2399\n",
      "[25,   100] loss: 0.2369\n",
      "[25,   150] loss: 0.2511\n",
      "[26,    50] loss: 0.2334\n",
      "[26,   100] loss: 0.2313\n",
      "[26,   150] loss: 0.2399\n",
      "[27,    50] loss: 0.2095\n",
      "[27,   100] loss: 0.2243\n",
      "[27,   150] loss: 0.2307\n",
      "[28,    50] loss: 0.2148\n",
      "[28,   100] loss: 0.2163\n",
      "[28,   150] loss: 0.2230\n",
      "[29,    50] loss: 0.2018\n",
      "[29,   100] loss: 0.2149\n",
      "[29,   150] loss: 0.2054\n",
      "[30,    50] loss: 0.2010\n",
      "[30,   100] loss: 0.1931\n",
      "[30,   150] loss: 0.2049\n",
      "[31,    50] loss: 0.1916\n",
      "[31,   100] loss: 0.1933\n",
      "[31,   150] loss: 0.1935\n",
      "[32,    50] loss: 0.1733\n",
      "[32,   100] loss: 0.1902\n",
      "[32,   150] loss: 0.1870\n",
      "[33,    50] loss: 0.1816\n",
      "[33,   100] loss: 0.1811\n",
      "[33,   150] loss: 0.1864\n",
      "[34,    50] loss: 0.1650\n",
      "[34,   100] loss: 0.1772\n",
      "[34,   150] loss: 0.1779\n",
      "[35,    50] loss: 0.1600\n",
      "[35,   100] loss: 0.1690\n",
      "[35,   150] loss: 0.1678\n",
      "[36,    50] loss: 0.1627\n",
      "[36,   100] loss: 0.1611\n",
      "[36,   150] loss: 0.1720\n",
      "[37,    50] loss: 0.1664\n",
      "[37,   100] loss: 0.1594\n",
      "[37,   150] loss: 0.1573\n",
      "[38,    50] loss: 0.1495\n",
      "[38,   100] loss: 0.1532\n",
      "[38,   150] loss: 0.1592\n",
      "[39,    50] loss: 0.1473\n",
      "[39,   100] loss: 0.1465\n",
      "[39,   150] loss: 0.1556\n",
      "[40,    50] loss: 0.1445\n",
      "[40,   100] loss: 0.1433\n",
      "[40,   150] loss: 0.1369\n",
      "[41,    50] loss: 0.1427\n",
      "[41,   100] loss: 0.1375\n",
      "[41,   150] loss: 0.1458\n",
      "[42,    50] loss: 0.1286\n",
      "[42,   100] loss: 0.1295\n",
      "[42,   150] loss: 0.1450\n",
      "[43,    50] loss: 0.1195\n",
      "[43,   100] loss: 0.1221\n",
      "[43,   150] loss: 0.1326\n",
      "[44,    50] loss: 0.1250\n",
      "[44,   100] loss: 0.1328\n",
      "[44,   150] loss: 0.1325\n",
      "[45,    50] loss: 0.1281\n",
      "[45,   100] loss: 0.1183\n",
      "[45,   150] loss: 0.1245\n",
      "[46,    50] loss: 0.1225\n",
      "[46,   100] loss: 0.1243\n",
      "[46,   150] loss: 0.1289\n",
      "[47,    50] loss: 0.1115\n",
      "[47,   100] loss: 0.1163\n",
      "[47,   150] loss: 0.1243\n",
      "[48,    50] loss: 0.1157\n",
      "[48,   100] loss: 0.1072\n",
      "[48,   150] loss: 0.1155\n",
      "[49,    50] loss: 0.1103\n",
      "[49,   100] loss: 0.1024\n",
      "[49,   150] loss: 0.1151\n",
      "[50,    50] loss: 0.1097\n",
      "[50,   100] loss: 0.1104\n",
      "[50,   150] loss: 0.1118\n",
      "----- Train Finished -----\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, trainloader, epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Test Start -----\n",
      "Accuracy of the model is: 85.8300 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85.83"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
